{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inception_block(nn.Module):\n",
    "    def __init__(self, in_channels, out_1x1, red_3x3, out_3x3, red_5x5, out_5x5, out_1x1pool):\n",
    "        super(Inception_block, self).__init__()\n",
    "\n",
    "        self.branch1 = conv_block(in_channels, out_1x1, kernel_size=1)\n",
    "        \n",
    "        self.branch2 = nn.Sequential(\n",
    "            conv_block(in_channels, red_3x3, kernel_size=1),\n",
    "            conv_block(red_3x3, out_3x3, kernel_size=3, padding=1)\n",
    "        )\n",
    "        \n",
    "        self.branch3 = nn.Sequential(\n",
    "            conv_block(in_channels, red_5x5, kernel_size=1),\n",
    "            conv_block(red_5x5, out_5x5, kernel_size=5, padding=2)\n",
    "        )\n",
    "        self.branch4 = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, stride=1, padding=1),\n",
    "            conv_block(in_channels, out_1x1pool, kernel_size=1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return torch.cat([self.branch1(x), self.branch2(x), self.branch3(x), self.branch4(x)], 1)\n",
    "        \n",
    "\n",
    "class conv_block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(conv_block, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, **kwargs)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.relu(self.batchnorm(self.conv(x)))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogLeNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=4):\n",
    "        super(GoogLeNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = conv_block(in_channels=in_channels, out_channels=64, kernel_size=(7,7), stride =(2,2), padding=(3,3))\n",
    "        \n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2, padding= 1)\n",
    "        self.conv2 = conv_block(64,192, kernel_size=3, stride=1, padding=1)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        #In this order: in)channels, out_1x1, red_3x3, out_3x3, red_5x5, out_5x5, out_1x1pool\n",
    "        self.inception3a = Inception_block(192, 64, 96, 128, 16, 32, 32)\n",
    "        self.inception3b = Inception_block(256, 128, 128, 192, 32, 96, 64)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.inception4a = Inception_block(480, 192, 96, 208, 16, 48, 64)\n",
    "        self.inception4b = Inception_block(512, 160, 112, 224, 24, 64, 64)\n",
    "        self.inception4c = Inception_block(512, 128, 128, 256, 24, 64, 64)\n",
    "        self.inception4d = Inception_block(512, 112, 144, 288, 32, 64, 64)\n",
    "        self.inception4e = Inception_block(528, 256, 160, 320, 32, 128, 128)\n",
    "        self.maxpool4 = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        \n",
    "        self.inception5a = Inception_block(832, 256, 160, 320, 32, 128, 128)\n",
    "        self.inception5b = Inception_block(832, 384, 192, 384, 48, 128, 128)\n",
    "        \n",
    "        self.avgpool = nn.AvgPool2d(kernel_size = 7, stride=1)\n",
    "        self.dropout = nn.Dropout(p=0.4)\n",
    "        self.fc1 = nn.Linear(1024,4)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        \n",
    "        x = self.inception3a(x)\n",
    "        x = self.inception3b(x)\n",
    "        x = self.maxpool3(x)\n",
    "        \n",
    "        x = self.inception4a(x)\n",
    "        x = self.inception4b(x)\n",
    "        x = self.inception4c(x)\n",
    "        x = self.inception4d(x)\n",
    "        x = self.inception4e(x)\n",
    "        x = self.maxpool4(x)\n",
    "        \n",
    "        x = self.inception5a(x)\n",
    "        x = self.inception5b(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    x = torch.randn(3, 3, 224, 224)\n",
    "    model = GoogLeNet()\n",
    "    print(model(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # resize image\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "train_dataset = ImageFolder(root=\"./AugmentedTrain\", transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        \n",
    "        for filename in os.listdir(root_dir):\n",
    "            if filename.endswith('.jpg'):\n",
    "                img_path = os.path.join(root_dir, filename)\n",
    "                self.samples.append((img_path, filename))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, filename = self.samples[idx]\n",
    "        image = Image.open(img_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, filename\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # resize image\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "\n",
    "train_subset, val_subset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_subset, batch_size=4, shuffle=False)\n",
    "\n",
    "test_dataset = TestDataset(root_dir=\"./Test/Test/\", transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Step [100/460], Loss: 0.9715\n",
      "Epoch [1/30], Step [200/460], Loss: 0.9038\n",
      "Epoch [1/30], Step [300/460], Loss: 1.2358\n",
      "Epoch [1/30], Step [400/460], Loss: 0.8059\n",
      "Epoch [1/30], Training Accuracy: 50.54%\n",
      "Epoch [1/30], Validation Loss: 0.9742, Validation Accuracy: 56.52%\n",
      "Epoch [2/30], Step [100/460], Loss: 0.8539\n",
      "Epoch [2/30], Step [200/460], Loss: 0.6499\n",
      "Epoch [2/30], Step [300/460], Loss: 1.0108\n",
      "Epoch [2/30], Step [400/460], Loss: 1.1007\n",
      "Epoch [2/30], Training Accuracy: 53.32%\n",
      "Epoch [2/30], Validation Loss: 0.9492, Validation Accuracy: 59.57%\n",
      "Epoch [3/30], Step [100/460], Loss: 1.5389\n",
      "Epoch [3/30], Step [200/460], Loss: 1.0304\n",
      "Epoch [3/30], Step [300/460], Loss: 0.9538\n",
      "Epoch [3/30], Step [400/460], Loss: 0.9812\n",
      "Epoch [3/30], Training Accuracy: 54.57%\n",
      "Epoch [3/30], Validation Loss: 0.9595, Validation Accuracy: 54.78%\n",
      "Epoch [4/30], Step [100/460], Loss: 0.7694\n",
      "Epoch [4/30], Step [200/460], Loss: 1.1109\n",
      "Epoch [4/30], Step [300/460], Loss: 0.6923\n",
      "Epoch [4/30], Step [400/460], Loss: 0.7961\n",
      "Epoch [4/30], Training Accuracy: 53.37%\n",
      "Epoch [4/30], Validation Loss: 1.0752, Validation Accuracy: 45.43%\n",
      "Epoch [5/30], Step [100/460], Loss: 1.3053\n",
      "Epoch [5/30], Step [200/460], Loss: 1.0511\n",
      "Epoch [5/30], Step [300/460], Loss: 0.7382\n",
      "Epoch [5/30], Step [400/460], Loss: 0.7490\n",
      "Epoch [5/30], Training Accuracy: 49.56%\n",
      "Epoch [5/30], Validation Loss: 0.9337, Validation Accuracy: 61.52%\n",
      "Epoch [6/30], Step [100/460], Loss: 0.7598\n",
      "Epoch [6/30], Step [200/460], Loss: 1.2963\n",
      "Epoch [6/30], Step [300/460], Loss: 1.5227\n",
      "Epoch [6/30], Step [400/460], Loss: 1.1169\n",
      "Epoch [6/30], Training Accuracy: 54.30%\n",
      "Epoch [6/30], Validation Loss: 0.9357, Validation Accuracy: 61.96%\n",
      "Epoch [7/30], Step [100/460], Loss: 0.7437\n",
      "Epoch [7/30], Step [200/460], Loss: 0.6401\n",
      "Epoch [7/30], Step [300/460], Loss: 1.4051\n",
      "Epoch [7/30], Step [400/460], Loss: 1.0379\n",
      "Epoch [7/30], Training Accuracy: 55.17%\n",
      "Epoch [7/30], Validation Loss: 0.9275, Validation Accuracy: 61.30%\n",
      "Epoch [8/30], Step [100/460], Loss: 1.2044\n",
      "Epoch [8/30], Step [200/460], Loss: 0.6163\n",
      "Epoch [8/30], Step [300/460], Loss: 0.9828\n",
      "Epoch [8/30], Step [400/460], Loss: 1.0541\n",
      "Epoch [8/30], Training Accuracy: 55.11%\n",
      "Epoch [8/30], Validation Loss: 0.9171, Validation Accuracy: 61.96%\n",
      "Epoch [9/30], Step [100/460], Loss: 0.7071\n",
      "Epoch [9/30], Step [200/460], Loss: 1.1942\n",
      "Epoch [9/30], Step [300/460], Loss: 0.4881\n",
      "Epoch [9/30], Step [400/460], Loss: 0.7133\n",
      "Epoch [9/30], Training Accuracy: 55.28%\n",
      "Epoch [9/30], Validation Loss: 0.8832, Validation Accuracy: 62.39%\n",
      "Epoch [10/30], Step [100/460], Loss: 1.2862\n",
      "Epoch [10/30], Step [200/460], Loss: 0.7058\n",
      "Epoch [10/30], Step [300/460], Loss: 0.7940\n",
      "Epoch [10/30], Step [400/460], Loss: 1.1805\n",
      "Epoch [10/30], Training Accuracy: 55.82%\n",
      "Epoch [10/30], Validation Loss: 0.9087, Validation Accuracy: 60.43%\n",
      "Epoch [11/30], Step [100/460], Loss: 0.7193\n",
      "Epoch [11/30], Step [200/460], Loss: 0.6657\n",
      "Epoch [11/30], Step [300/460], Loss: 1.0860\n",
      "Epoch [11/30], Step [400/460], Loss: 0.8445\n",
      "Epoch [11/30], Training Accuracy: 56.96%\n",
      "Epoch [11/30], Validation Loss: 0.8907, Validation Accuracy: 62.83%\n",
      "Epoch [12/30], Step [100/460], Loss: 1.0336\n",
      "Epoch [12/30], Step [200/460], Loss: 0.8731\n",
      "Epoch [12/30], Step [300/460], Loss: 1.1133\n",
      "Epoch [12/30], Step [400/460], Loss: 0.6056\n",
      "Epoch [12/30], Training Accuracy: 55.55%\n",
      "Epoch [12/30], Validation Loss: 0.9045, Validation Accuracy: 61.96%\n",
      "Epoch [13/30], Step [100/460], Loss: 0.7473\n",
      "Epoch [13/30], Step [200/460], Loss: 0.7319\n",
      "Epoch [13/30], Step [300/460], Loss: 0.9882\n",
      "Epoch [13/30], Step [400/460], Loss: 1.2825\n",
      "Epoch [13/30], Training Accuracy: 55.77%\n",
      "Epoch [13/30], Validation Loss: 0.8899, Validation Accuracy: 63.91%\n",
      "Epoch [14/30], Step [100/460], Loss: 0.9239\n",
      "Epoch [14/30], Step [200/460], Loss: 0.7653\n",
      "Epoch [14/30], Step [300/460], Loss: 0.9307\n",
      "Epoch [14/30], Step [400/460], Loss: 1.0716\n",
      "Epoch [14/30], Training Accuracy: 55.33%\n",
      "Epoch [14/30], Validation Loss: 0.9001, Validation Accuracy: 63.70%\n",
      "Epoch [15/30], Step [100/460], Loss: 1.0644\n",
      "Epoch [15/30], Step [200/460], Loss: 0.9265\n",
      "Epoch [15/30], Step [300/460], Loss: 1.8013\n",
      "Epoch [15/30], Step [400/460], Loss: 1.0566\n",
      "Epoch [15/30], Training Accuracy: 55.22%\n",
      "Epoch [15/30], Validation Loss: 0.9196, Validation Accuracy: 63.70%\n",
      "Epoch [16/30], Step [100/460], Loss: 0.6495\n",
      "Epoch [16/30], Step [200/460], Loss: 0.7009\n",
      "Epoch [16/30], Step [300/460], Loss: 0.5782\n",
      "Epoch [16/30], Step [400/460], Loss: 1.8186\n",
      "Epoch [16/30], Training Accuracy: 56.15%\n",
      "Epoch [16/30], Validation Loss: 0.8872, Validation Accuracy: 61.52%\n",
      "Epoch [17/30], Step [100/460], Loss: 0.6448\n",
      "Epoch [17/30], Step [200/460], Loss: 1.1906\n",
      "Epoch [17/30], Step [300/460], Loss: 0.9706\n",
      "Epoch [17/30], Step [400/460], Loss: 0.5311\n",
      "Epoch [17/30], Training Accuracy: 56.42%\n",
      "Epoch [17/30], Validation Loss: 0.8958, Validation Accuracy: 61.09%\n",
      "Epoch [18/30], Step [100/460], Loss: 1.0708\n",
      "Epoch [18/30], Step [200/460], Loss: 0.7730\n",
      "Epoch [18/30], Step [300/460], Loss: 0.5289\n",
      "Epoch [18/30], Step [400/460], Loss: 1.6718\n",
      "Epoch [18/30], Training Accuracy: 57.29%\n",
      "Epoch [18/30], Validation Loss: 0.9166, Validation Accuracy: 57.83%\n",
      "Epoch [19/30], Step [100/460], Loss: 1.0463\n",
      "Epoch [19/30], Step [200/460], Loss: 1.0906\n",
      "Epoch [19/30], Step [300/460], Loss: 1.5546\n",
      "Epoch [19/30], Step [400/460], Loss: 1.3626\n",
      "Epoch [19/30], Training Accuracy: 57.18%\n",
      "Epoch [19/30], Validation Loss: 0.8894, Validation Accuracy: 62.17%\n",
      "Epoch [20/30], Step [100/460], Loss: 0.6277\n",
      "Epoch [20/30], Step [200/460], Loss: 0.7440\n",
      "Epoch [20/30], Step [300/460], Loss: 0.5057\n",
      "Epoch [20/30], Step [400/460], Loss: 0.7182\n",
      "Epoch [20/30], Training Accuracy: 56.91%\n",
      "Epoch [20/30], Validation Loss: 0.9029, Validation Accuracy: 62.61%\n",
      "Epoch [21/30], Step [100/460], Loss: 0.8654\n",
      "Epoch [21/30], Step [200/460], Loss: 0.4980\n",
      "Epoch [21/30], Step [300/460], Loss: 0.8391\n",
      "Epoch [21/30], Step [400/460], Loss: 0.7996\n",
      "Epoch [21/30], Training Accuracy: 57.07%\n",
      "Epoch [21/30], Validation Loss: 0.9067, Validation Accuracy: 63.26%\n",
      "Epoch [22/30], Step [100/460], Loss: 0.9892\n",
      "Epoch [22/30], Step [200/460], Loss: 0.9283\n",
      "Epoch [22/30], Step [300/460], Loss: 0.9645\n",
      "Epoch [22/30], Step [400/460], Loss: 0.9434\n",
      "Epoch [22/30], Training Accuracy: 58.00%\n",
      "Epoch [22/30], Validation Loss: 0.9484, Validation Accuracy: 56.52%\n",
      "Epoch [23/30], Step [100/460], Loss: 1.5298\n",
      "Epoch [23/30], Step [200/460], Loss: 0.4394\n",
      "Epoch [23/30], Step [300/460], Loss: 1.1218\n",
      "Epoch [23/30], Step [400/460], Loss: 0.7608\n",
      "Epoch [23/30], Training Accuracy: 59.14%\n",
      "Epoch [23/30], Validation Loss: 0.9301, Validation Accuracy: 55.87%\n",
      "Epoch [24/30], Step [100/460], Loss: 1.5188\n",
      "Epoch [24/30], Step [200/460], Loss: 0.6326\n",
      "Epoch [24/30], Step [300/460], Loss: 0.5948\n",
      "Epoch [24/30], Step [400/460], Loss: 0.9385\n",
      "Epoch [24/30], Training Accuracy: 57.45%\n",
      "Epoch [24/30], Validation Loss: 0.9053, Validation Accuracy: 61.96%\n",
      "Epoch [25/30], Step [100/460], Loss: 0.4081\n",
      "Epoch [25/30], Step [200/460], Loss: 1.3336\n",
      "Epoch [25/30], Step [300/460], Loss: 1.1579\n",
      "Epoch [25/30], Step [400/460], Loss: 0.6814\n",
      "Epoch [25/30], Training Accuracy: 57.56%\n",
      "Epoch [25/30], Validation Loss: 0.8815, Validation Accuracy: 62.61%\n",
      "Epoch [26/30], Step [100/460], Loss: 1.9489\n",
      "Epoch [26/30], Step [200/460], Loss: 0.6335\n",
      "Epoch [26/30], Step [300/460], Loss: 0.7931\n",
      "Epoch [26/30], Step [400/460], Loss: 0.9520\n",
      "Epoch [26/30], Training Accuracy: 58.11%\n",
      "Epoch [26/30], Validation Loss: 0.8778, Validation Accuracy: 62.61%\n",
      "Epoch [27/30], Step [100/460], Loss: 0.8034\n",
      "Epoch [27/30], Step [200/460], Loss: 0.6602\n",
      "Epoch [27/30], Step [300/460], Loss: 0.8913\n",
      "Epoch [27/30], Step [400/460], Loss: 1.6850\n",
      "Epoch [27/30], Training Accuracy: 57.07%\n",
      "Epoch [27/30], Validation Loss: 0.9025, Validation Accuracy: 61.96%\n",
      "Epoch [28/30], Step [100/460], Loss: 0.6448\n",
      "Epoch [28/30], Step [200/460], Loss: 1.7873\n",
      "Epoch [28/30], Step [300/460], Loss: 1.2933\n",
      "Epoch [28/30], Step [400/460], Loss: 0.8499\n",
      "Epoch [28/30], Training Accuracy: 59.47%\n",
      "Epoch [28/30], Validation Loss: 0.8835, Validation Accuracy: 62.83%\n",
      "Epoch [29/30], Step [100/460], Loss: 0.5089\n",
      "Epoch [29/30], Step [200/460], Loss: 0.5434\n",
      "Epoch [29/30], Step [300/460], Loss: 1.1944\n",
      "Epoch [29/30], Step [400/460], Loss: 1.1636\n",
      "Epoch [29/30], Training Accuracy: 58.81%\n",
      "Epoch [29/30], Validation Loss: 0.8921, Validation Accuracy: 60.00%\n",
      "Epoch [30/30], Step [100/460], Loss: 2.0301\n",
      "Epoch [30/30], Step [200/460], Loss: 0.6775\n",
      "Epoch [30/30], Step [300/460], Loss: 1.1264\n",
      "Epoch [30/30], Step [400/460], Loss: 1.2602\n",
      "Epoch [30/30], Training Accuracy: 58.05%\n",
      "Epoch [30/30], Validation Loss: 0.8852, Validation Accuracy: 61.96%\n"
     ]
    }
   ],
   "source": [
    "# 1. Initialize the Model, Loss, and Optimizer\n",
    "model = GoogLeNet(num_classes=4).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 30\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    # 2. Training Loop\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        \n",
    "        _, predicted_train = outputs.max(1)\n",
    "        correct_train += predicted_train.eq(target).sum().item()\n",
    "        total_train += target.size(0)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_accuracy = 100. * correct_train / total_train\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Accuracy: {train_accuracy:.2f}%\")\n",
    "    \n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            total_val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "   \n",
    "    val_accuracy = 100. * correct / len(val_subset)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "model.to(device)\n",
    "model.eval()  \n",
    "\n",
    "filenames = []\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():  \n",
    "    for data, filename in test_loader:  \n",
    "        data = data.to(device)\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs, 1)  # Find the class index with the maximum value for each sample\n",
    "        filenames.extend(filename)\n",
    "        predictions.extend(predicted.cpu().numpy().tolist())\n",
    "\n",
    "model.train()  # Set the model back to training mode\n",
    "import pandas as pd\n",
    "\n",
    "df_output = pd.DataFrame({\n",
    "    'Filename': filenames,\n",
    "    'Prediction': predictions \n",
    "})\n",
    "\n",
    "df_output.to_csv('ggnet_predictions.csv', index=False, header=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorLabelDataset(Dataset):\n",
    "    def __init__(self, original_dataset):\n",
    "        self.original_dataset = original_dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.original_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data, label = self.original_dataset[idx]\n",
    "        return data, torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "\n",
    "train_subset, val_subset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# Wrap train_subset\n",
    "tensor_label_train_subset = TensorLabelDataset(train_subset)\n",
    "train_loader = DataLoader(tensor_label_train_subset, batch_size=4, shuffle=True, drop_last=True) # use tensor_label_train_subset here\n",
    "\n",
    "val_loader = DataLoader(val_subset, batch_size=4, shuffle=False)\n",
    "\n",
    "test_dataset = TestDataset(root_dir=\"./Test/Test/\", transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "print(data.shape, target.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Training Accuracy: 52.94%\n",
      "Epoch [1/30], Validation Loss: 0.9505, Validation Accuracy: 62.17%\n",
      "Epoch [2/30], Training Accuracy: 56.09%\n",
      "Epoch [2/30], Validation Loss: 0.9167, Validation Accuracy: 64.13%\n",
      "Epoch [3/30], Training Accuracy: 58.32%\n",
      "Epoch [3/30], Validation Loss: 0.9415, Validation Accuracy: 58.04%\n",
      "Epoch [4/30], Training Accuracy: 58.27%\n",
      "Epoch [4/30], Validation Loss: 0.9268, Validation Accuracy: 61.09%\n",
      "Epoch [5/30], Training Accuracy: 59.58%\n",
      "Epoch [5/30], Validation Loss: 0.9498, Validation Accuracy: 64.57%\n",
      "Epoch [6/30], Training Accuracy: 59.66%\n",
      "Epoch [6/30], Validation Loss: 0.8770, Validation Accuracy: 62.83%\n",
      "Epoch [7/30], Training Accuracy: 60.28%\n",
      "Epoch [7/30], Validation Loss: 0.8948, Validation Accuracy: 63.70%\n",
      "Epoch [8/30], Training Accuracy: 58.81%\n",
      "Epoch [8/30], Validation Loss: 0.9281, Validation Accuracy: 63.70%\n",
      "Epoch [9/30], Training Accuracy: 59.85%\n",
      "Epoch [9/30], Validation Loss: 0.9890, Validation Accuracy: 52.83%\n",
      "Epoch [10/30], Training Accuracy: 59.96%\n",
      "Epoch [10/30], Validation Loss: 0.8731, Validation Accuracy: 62.39%\n",
      "Epoch [11/30], Training Accuracy: 59.74%\n",
      "Epoch [11/30], Validation Loss: 0.8589, Validation Accuracy: 63.26%\n",
      "Epoch [12/30], Training Accuracy: 58.87%\n",
      "Epoch [12/30], Validation Loss: 0.8950, Validation Accuracy: 60.87%\n",
      "Epoch [13/30], Training Accuracy: 61.04%\n",
      "Epoch [13/30], Validation Loss: 0.8381, Validation Accuracy: 65.65%\n",
      "Epoch [14/30], Training Accuracy: 60.28%\n",
      "Epoch [14/30], Validation Loss: 0.8232, Validation Accuracy: 65.87%\n",
      "Epoch [15/30], Training Accuracy: 61.60%\n",
      "Epoch [15/30], Validation Loss: 0.8403, Validation Accuracy: 64.13%\n",
      "Epoch [16/30], Training Accuracy: 60.99%\n",
      "Epoch [16/30], Validation Loss: 0.8717, Validation Accuracy: 62.39%\n",
      "Epoch [17/30], Training Accuracy: 59.79%\n",
      "Epoch [17/30], Validation Loss: 0.8675, Validation Accuracy: 63.48%\n",
      "Epoch [18/30], Training Accuracy: 60.06%\n",
      "Epoch [18/30], Validation Loss: 0.8163, Validation Accuracy: 64.57%\n",
      "Epoch [19/30], Training Accuracy: 60.77%\n",
      "Epoch [19/30], Validation Loss: 0.8347, Validation Accuracy: 64.57%\n",
      "Epoch [20/30], Training Accuracy: 61.37%\n",
      "Epoch [20/30], Validation Loss: 0.8431, Validation Accuracy: 63.48%\n",
      "Epoch [21/30], Training Accuracy: 61.21%\n",
      "Epoch [21/30], Validation Loss: 0.8860, Validation Accuracy: 56.09%\n",
      "Epoch [22/30], Training Accuracy: 60.59%\n",
      "Epoch [22/30], Validation Loss: 0.8431, Validation Accuracy: 61.30%\n",
      "Epoch [23/30], Training Accuracy: 63.44%\n",
      "Epoch [23/30], Validation Loss: 0.8289, Validation Accuracy: 63.91%\n",
      "Epoch [24/30], Training Accuracy: 61.21%\n",
      "Epoch [24/30], Validation Loss: 0.9156, Validation Accuracy: 61.96%\n",
      "Epoch [25/30], Training Accuracy: 63.96%\n",
      "Epoch [25/30], Validation Loss: 0.8484, Validation Accuracy: 64.78%\n",
      "Epoch [26/30], Training Accuracy: 64.48%\n",
      "Epoch [26/30], Validation Loss: 1.0265, Validation Accuracy: 53.04%\n",
      "Epoch [27/30], Training Accuracy: 62.58%\n",
      "Epoch [27/30], Validation Loss: 0.9029, Validation Accuracy: 63.04%\n",
      "Epoch [28/30], Training Accuracy: 65.14%\n",
      "Epoch [28/30], Validation Loss: 0.8232, Validation Accuracy: 64.13%\n",
      "Epoch [29/30], Training Accuracy: 63.44%\n",
      "Epoch [29/30], Validation Loss: 0.7809, Validation Accuracy: 63.26%\n",
      "Epoch [30/30], Training Accuracy: 64.96%\n",
      "Epoch [30/30], Validation Loss: 0.8444, Validation Accuracy: 65.00%\n"
     ]
    }
   ],
   "source": [
    "class PseudoLabeledDataset(Dataset):\n",
    "    def __init__(self, data_list):\n",
    "        self.data_list = data_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data, label = self.data_list[idx]\n",
    "        return data, torch.tensor(label, dtype=torch.long)  # Explicitly casting to tensor\n",
    "\n",
    "# Initialize the Model, Loss, and Optimizer\n",
    "model = GoogLeNet(num_classes=4).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 30\n",
    "\n",
    "# Pseudo-labeling threshold\n",
    "threshold = 0.95\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    # Pseudo-labeling: get the pseudo-labels for the test data\n",
    "    model.eval()\n",
    "    pseudo_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data, _ in test_loader:\n",
    "            data = data.to(device)\n",
    "            outputs = F.softmax(model(data), dim=1)\n",
    "            _, predicted = outputs.max(1)\n",
    "            # Only keep predictions with confidence above the threshold\n",
    "            mask = outputs.max(1)[0] > threshold\n",
    "            for i in range(len(mask)):\n",
    "                if mask[i]:\n",
    "                    pseudo_labels.append((data[i].cpu(), predicted[i].item()))  # Using integer here, but it's casted to tensor when getting item\n",
    "\n",
    "    # Concatenate pseudo-labeled data with original training data\n",
    "    pseudo_dataset = PseudoLabeledDataset(pseudo_labels)\n",
    "    #combined_dataset = ConcatDataset([train_dataset, pseudo_dataset])\n",
    "    combined_dataset = ConcatDataset([tensor_label_train_subset, pseudo_dataset])\n",
    "\n",
    "    combined_loader = DataLoader(combined_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    # Training Loop with pseudo-labeled data\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(combined_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(data)\n",
    "        #loss = criterion(outputs, target.squeeze())  # Use squeeze in case of any singleton dimensions\n",
    "        loss = criterion(outputs, target)\n",
    "        \n",
    "        _, predicted_train = outputs.max(1)\n",
    "        correct_train += predicted_train.eq(target).sum().item()\n",
    "        total_train += target.size(0)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(combined_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_accuracy = 100. * correct_train / total_train\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Accuracy: {train_accuracy:.2f}%\")\n",
    "    \n",
    "    # Validation Loop\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            total_val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "   \n",
    "    val_accuracy = 100. * correct / len(val_subset)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "model.to(device)\n",
    "model.eval()  \n",
    "\n",
    "filenames = []\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():  \n",
    "    for data, filename in test_loader:  \n",
    "        data = data.to(device)\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs, 1)  # Find the class index with the maximum value for each sample\n",
    "        filenames.extend(filename)\n",
    "        predictions.extend(predicted.cpu().numpy().tolist())\n",
    "\n",
    "model.train()  # Set the model back to training mode\n",
    "import pandas as pd\n",
    "\n",
    "df_output = pd.DataFrame({\n",
    "    'Filename': filenames,\n",
    "    'Prediction': predictions \n",
    "})\n",
    "\n",
    "df_output.to_csv('Ggnet_Pl_predictions.csv', index=False, header=False) \n",
    "#61%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
