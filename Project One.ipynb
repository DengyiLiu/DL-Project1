{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "009e8fc2",
   "metadata": {},
   "source": [
    "# 1. Build your own convolutional neural network using pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "133be475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec4bc551",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # resize image\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "train_dataset = ImageFolder(root=\"./AugmentedTrain\", transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22d5164c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        \n",
    "        for filename in os.listdir(root_dir):\n",
    "            if filename.endswith('.jpg'):\n",
    "                img_path = os.path.join(root_dir, filename)\n",
    "                self.samples.append((img_path, filename))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, filename = self.samples[idx]\n",
    "        image = Image.open(img_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, filename\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # resize image\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc54a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "\n",
    "train_subset, val_subset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_subset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_subset, batch_size=4, shuffle=False)\n",
    "\n",
    "test_dataset = TestDataset(root_dir=\"./Test/Test/\", transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0060d691",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),                   \n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            \n",
    "            nn.Conv2d(128, 256, kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),           \n",
    "\n",
    "            nn.Conv2d(256, 384, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ReLU(),  \n",
    "\n",
    "            nn.Conv2d(384, 512, kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),  \n",
    "\n",
    "            nn.Conv2d(512, 1024, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(),   \n",
    "            \n",
    "            nn.Conv2d(1024, 2048, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(2048),\n",
    "            nn.ReLU(),  \n",
    "            \n",
    "            nn.Conv2d(2048, 512, kernel_size=5, stride=2, padding=2),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),  \n",
    "        )\n",
    "        self.fc_block = nn.Sequential(\n",
    "            nn.Linear(25088, 1024),   # Adjust this input size based on the output of your last conv layer\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            \n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.conv_block(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = self.fc_block(x)\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c45b84",
   "metadata": {},
   "source": [
    "# 2. Train your model using cow teat datasets (you may need to use  Google Colab (or Kaggle) with GPU to train your code) \n",
    "\n",
    "### (1) use torchvision.datasets.ImageFolder for the training dataset\n",
    "### (2) use custom dataloader for test dataset (return image tensor and file name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50effdac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Step [100/230], Loss: 1.1656\n",
      "Epoch [1/30], Step [200/230], Loss: 0.9608\n",
      "Epoch [1/30], Training Accuracy: 51.58%\n",
      "Epoch [1/30], Validation Loss: 1.0533, Validation Accuracy: 51.30%\n",
      "Epoch [2/30], Step [100/230], Loss: 1.3847\n",
      "Epoch [2/30], Step [200/230], Loss: 0.8401\n",
      "Epoch [2/30], Training Accuracy: 51.14%\n",
      "Epoch [2/30], Validation Loss: 1.0071, Validation Accuracy: 63.91%\n",
      "Epoch [3/30], Step [100/230], Loss: 0.5602\n",
      "Epoch [3/30], Step [200/230], Loss: 0.8500\n",
      "Epoch [3/30], Training Accuracy: 51.47%\n",
      "Epoch [3/30], Validation Loss: 1.1005, Validation Accuracy: 55.22%\n",
      "Epoch [4/30], Step [100/230], Loss: 1.1984\n",
      "Epoch [4/30], Step [200/230], Loss: 0.5826\n",
      "Epoch [4/30], Training Accuracy: 50.71%\n",
      "Epoch [4/30], Validation Loss: 2.7109, Validation Accuracy: 43.91%\n",
      "Epoch [5/30], Step [100/230], Loss: 0.7540\n",
      "Epoch [5/30], Step [200/230], Loss: 0.7690\n",
      "Epoch [5/30], Training Accuracy: 49.95%\n",
      "Epoch [5/30], Validation Loss: 1.0394, Validation Accuracy: 43.04%\n",
      "Epoch [6/30], Step [100/230], Loss: 0.7094\n",
      "Epoch [6/30], Step [200/230], Loss: 1.3774\n",
      "Epoch [6/30], Training Accuracy: 50.05%\n",
      "Epoch [6/30], Validation Loss: 0.9810, Validation Accuracy: 64.78%\n",
      "Epoch [7/30], Step [100/230], Loss: 2.1811\n",
      "Epoch [7/30], Step [200/230], Loss: 1.0210\n",
      "Epoch [7/30], Training Accuracy: 49.51%\n",
      "Epoch [7/30], Validation Loss: 1.0526, Validation Accuracy: 63.48%\n",
      "Epoch [8/30], Step [100/230], Loss: 1.2962\n",
      "Epoch [8/30], Step [200/230], Loss: 0.7743\n",
      "Epoch [8/30], Training Accuracy: 47.12%\n",
      "Epoch [8/30], Validation Loss: 1.0299, Validation Accuracy: 53.91%\n",
      "Epoch [9/30], Step [100/230], Loss: 1.0162\n",
      "Epoch [9/30], Step [200/230], Loss: 0.5465\n",
      "Epoch [9/30], Training Accuracy: 48.86%\n",
      "Epoch [9/30], Validation Loss: 1.0089, Validation Accuracy: 57.39%\n",
      "Epoch [10/30], Step [100/230], Loss: 0.9795\n",
      "Epoch [10/30], Step [200/230], Loss: 0.8438\n",
      "Epoch [10/30], Training Accuracy: 47.12%\n",
      "Epoch [10/30], Validation Loss: 1.0397, Validation Accuracy: 60.87%\n",
      "Epoch [11/30], Step [100/230], Loss: 0.9036\n",
      "Epoch [11/30], Step [200/230], Loss: 0.7758\n",
      "Epoch [11/30], Training Accuracy: 51.25%\n",
      "Epoch [11/30], Validation Loss: 0.9458, Validation Accuracy: 66.52%\n",
      "Epoch [12/30], Step [100/230], Loss: 0.5474\n",
      "Epoch [12/30], Step [200/230], Loss: 0.7288\n",
      "Epoch [12/30], Training Accuracy: 52.99%\n",
      "Epoch [12/30], Validation Loss: 0.9676, Validation Accuracy: 60.00%\n",
      "Epoch [13/30], Step [100/230], Loss: 0.6933\n",
      "Epoch [13/30], Step [200/230], Loss: 0.8522\n",
      "Epoch [13/30], Training Accuracy: 50.60%\n",
      "Epoch [13/30], Validation Loss: 1.2118, Validation Accuracy: 36.96%\n",
      "Epoch [14/30], Step [100/230], Loss: 0.9249\n",
      "Epoch [14/30], Step [200/230], Loss: 0.7146\n",
      "Epoch [14/30], Training Accuracy: 51.58%\n",
      "Epoch [14/30], Validation Loss: 0.9981, Validation Accuracy: 53.91%\n",
      "Epoch [15/30], Step [100/230], Loss: 0.8476\n",
      "Epoch [15/30], Step [200/230], Loss: 0.5588\n",
      "Epoch [15/30], Training Accuracy: 54.30%\n",
      "Epoch [15/30], Validation Loss: 0.9723, Validation Accuracy: 62.17%\n",
      "Epoch [16/30], Step [100/230], Loss: 1.1649\n",
      "Epoch [16/30], Step [200/230], Loss: 0.9945\n",
      "Epoch [16/30], Training Accuracy: 52.01%\n",
      "Epoch [16/30], Validation Loss: 0.9325, Validation Accuracy: 64.35%\n",
      "Epoch [17/30], Step [100/230], Loss: 1.7607\n",
      "Epoch [17/30], Step [200/230], Loss: 1.2517\n",
      "Epoch [17/30], Training Accuracy: 52.88%\n",
      "Epoch [17/30], Validation Loss: 0.9455, Validation Accuracy: 62.17%\n",
      "Epoch [18/30], Step [100/230], Loss: 0.7386\n",
      "Epoch [18/30], Step [200/230], Loss: 0.6009\n",
      "Epoch [18/30], Training Accuracy: 51.03%\n",
      "Epoch [18/30], Validation Loss: 0.9870, Validation Accuracy: 46.96%\n",
      "Epoch [19/30], Step [100/230], Loss: 0.6482\n",
      "Epoch [19/30], Step [200/230], Loss: 0.6697\n",
      "Epoch [19/30], Training Accuracy: 52.77%\n",
      "Epoch [19/30], Validation Loss: 0.9215, Validation Accuracy: 66.96%\n",
      "Epoch [20/30], Step [100/230], Loss: 0.7748\n",
      "Epoch [20/30], Step [200/230], Loss: 0.9256\n",
      "Epoch [20/30], Training Accuracy: 53.21%\n",
      "Epoch [20/30], Validation Loss: 1.0666, Validation Accuracy: 46.52%\n",
      "Epoch [21/30], Step [100/230], Loss: 1.4412\n",
      "Epoch [21/30], Step [200/230], Loss: 0.9296\n",
      "Epoch [21/30], Training Accuracy: 50.92%\n",
      "Epoch [21/30], Validation Loss: 0.9801, Validation Accuracy: 63.91%\n",
      "Epoch [22/30], Step [100/230], Loss: 0.7306\n",
      "Epoch [22/30], Step [200/230], Loss: 0.9647\n",
      "Epoch [22/30], Training Accuracy: 56.58%\n",
      "Epoch [22/30], Validation Loss: 0.9347, Validation Accuracy: 66.09%\n",
      "Epoch [23/30], Step [100/230], Loss: 1.3100\n",
      "Epoch [23/30], Step [200/230], Loss: 0.9979\n",
      "Epoch [23/30], Training Accuracy: 54.41%\n",
      "Epoch [23/30], Validation Loss: 0.9173, Validation Accuracy: 64.78%\n",
      "Epoch [24/30], Step [100/230], Loss: 0.7379\n",
      "Epoch [24/30], Step [200/230], Loss: 0.6419\n",
      "Epoch [24/30], Training Accuracy: 52.99%\n",
      "Epoch [24/30], Validation Loss: 0.9402, Validation Accuracy: 63.48%\n",
      "Epoch [25/30], Step [100/230], Loss: 0.6832\n",
      "Epoch [25/30], Step [200/230], Loss: 0.9829\n",
      "Epoch [25/30], Training Accuracy: 55.82%\n",
      "Epoch [25/30], Validation Loss: 1.0048, Validation Accuracy: 54.78%\n",
      "Epoch [26/30], Step [100/230], Loss: 1.6394\n",
      "Epoch [26/30], Step [200/230], Loss: 0.5975\n",
      "Epoch [26/30], Training Accuracy: 52.34%\n",
      "Epoch [26/30], Validation Loss: 0.9479, Validation Accuracy: 62.17%\n",
      "Epoch [27/30], Step [100/230], Loss: 1.0523\n",
      "Epoch [27/30], Step [200/230], Loss: 0.8149\n",
      "Epoch [27/30], Training Accuracy: 53.65%\n",
      "Epoch [27/30], Validation Loss: 0.9303, Validation Accuracy: 66.96%\n",
      "Epoch [28/30], Step [100/230], Loss: 1.3236\n",
      "Epoch [28/30], Step [200/230], Loss: 0.5818\n",
      "Epoch [28/30], Training Accuracy: 57.45%\n",
      "Epoch [28/30], Validation Loss: 0.9468, Validation Accuracy: 67.83%\n",
      "Epoch [29/30], Step [100/230], Loss: 0.6638\n",
      "Epoch [29/30], Step [200/230], Loss: 0.6879\n",
      "Epoch [29/30], Training Accuracy: 53.97%\n",
      "Epoch [29/30], Validation Loss: 0.9317, Validation Accuracy: 64.35%\n",
      "Epoch [30/30], Step [100/230], Loss: 0.7648\n",
      "Epoch [30/30], Step [200/230], Loss: 0.6742\n",
      "Epoch [30/30], Training Accuracy: 57.56%\n",
      "Epoch [30/30], Validation Loss: 0.9138, Validation Accuracy: 66.52%\n"
     ]
    }
   ],
   "source": [
    "# 1. Initialize the Model, Loss, and Optimizer\n",
    "model = ConvNet(num_classes=4).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 30\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    # 2. Training Loop\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "        \n",
    "        _, predicted_train = outputs.max(1)\n",
    "        correct_train += predicted_train.eq(target).sum().item()\n",
    "        total_train += target.size(0)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_accuracy = 100. * correct_train / total_train\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Accuracy: {train_accuracy:.2f}%\")\n",
    "    \n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            total_val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "   \n",
    "    val_accuracy = 100. * correct / len(val_subset)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "829815f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorLabelDataset(Dataset):\n",
    "    def __init__(self, original_dataset):\n",
    "        self.original_dataset = original_dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.original_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data, label = self.original_dataset[idx]\n",
    "        return data, torch.tensor(label, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12d24e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "\n",
    "train_subset, val_subset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# Wrap train_subset\n",
    "tensor_label_train_subset = TensorLabelDataset(train_subset)\n",
    "train_loader = DataLoader(tensor_label_train_subset, batch_size=4, shuffle=True, drop_last=True) # use tensor_label_train_subset here\n",
    "\n",
    "val_loader = DataLoader(val_subset, batch_size=4, shuffle=False)\n",
    "\n",
    "test_dataset = TestDataset(root_dir=\"./Test/Test/\", transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a18fe2",
   "metadata": {},
   "source": [
    "## Pseudo labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b181aaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Training Accuracy: 53.75%\n",
      "Epoch [1/30], Validation Loss: 1.0243, Validation Accuracy: 51.52%\n",
      "Epoch [2/30], Training Accuracy: 57.29%\n",
      "Epoch [2/30], Validation Loss: 0.9903, Validation Accuracy: 59.78%\n",
      "Epoch [3/30], Training Accuracy: 57.48%\n",
      "Epoch [3/30], Validation Loss: 1.0893, Validation Accuracy: 60.22%\n",
      "Epoch [4/30], Training Accuracy: 57.65%\n",
      "Epoch [4/30], Validation Loss: 1.0196, Validation Accuracy: 57.17%\n",
      "Epoch [5/30], Training Accuracy: 58.04%\n",
      "Epoch [5/30], Validation Loss: 1.0189, Validation Accuracy: 57.17%\n",
      "Epoch [6/30], Training Accuracy: 58.77%\n",
      "Epoch [6/30], Validation Loss: 0.9970, Validation Accuracy: 57.39%\n",
      "Epoch [7/30], Training Accuracy: 57.62%\n",
      "Epoch [7/30], Validation Loss: 1.0772, Validation Accuracy: 57.83%\n",
      "Epoch [8/30], Training Accuracy: 58.37%\n",
      "Epoch [8/30], Validation Loss: 0.9723, Validation Accuracy: 59.57%\n",
      "Epoch [9/30], Training Accuracy: 59.31%\n",
      "Epoch [9/30], Validation Loss: 1.0242, Validation Accuracy: 52.83%\n",
      "Epoch [10/30], Training Accuracy: 58.92%\n",
      "Epoch [10/30], Validation Loss: 0.9640, Validation Accuracy: 60.87%\n",
      "Epoch [11/30], Training Accuracy: 58.26%\n",
      "Epoch [11/30], Validation Loss: 0.9717, Validation Accuracy: 58.26%\n",
      "Epoch [12/30], Training Accuracy: 59.24%\n",
      "Epoch [12/30], Validation Loss: 1.0002, Validation Accuracy: 48.70%\n",
      "Epoch [13/30], Training Accuracy: 58.79%\n",
      "Epoch [13/30], Validation Loss: 1.0005, Validation Accuracy: 59.57%\n",
      "Epoch [14/30], Training Accuracy: 58.87%\n",
      "Epoch [14/30], Validation Loss: 0.9856, Validation Accuracy: 55.87%\n",
      "Epoch [15/30], Training Accuracy: 60.84%\n",
      "Epoch [15/30], Validation Loss: 0.9714, Validation Accuracy: 58.26%\n",
      "Epoch [16/30], Training Accuracy: 60.01%\n",
      "Epoch [16/30], Validation Loss: 1.0568, Validation Accuracy: 52.39%\n",
      "Epoch [17/30], Training Accuracy: 62.00%\n",
      "Epoch [17/30], Validation Loss: 0.9910, Validation Accuracy: 59.78%\n",
      "Epoch [18/30], Training Accuracy: 59.81%\n",
      "Epoch [18/30], Validation Loss: 1.0418, Validation Accuracy: 55.43%\n",
      "Epoch [19/30], Training Accuracy: 59.89%\n",
      "Epoch [19/30], Validation Loss: 0.9618, Validation Accuracy: 59.13%\n",
      "Epoch [20/30], Training Accuracy: 60.17%\n",
      "Epoch [20/30], Validation Loss: 0.9736, Validation Accuracy: 56.74%\n",
      "Epoch [21/30], Training Accuracy: 62.69%\n",
      "Epoch [21/30], Validation Loss: 1.0631, Validation Accuracy: 50.00%\n",
      "Epoch [22/30], Training Accuracy: 63.24%\n",
      "Epoch [22/30], Validation Loss: 0.9706, Validation Accuracy: 55.43%\n",
      "Epoch [23/30], Training Accuracy: 62.72%\n",
      "Epoch [23/30], Validation Loss: 1.0014, Validation Accuracy: 57.39%\n",
      "Epoch [24/30], Training Accuracy: 64.60%\n",
      "Epoch [24/30], Validation Loss: 0.9949, Validation Accuracy: 58.04%\n",
      "Epoch [25/30], Training Accuracy: 63.77%\n",
      "Epoch [25/30], Validation Loss: 1.0407, Validation Accuracy: 57.17%\n",
      "Epoch [26/30], Training Accuracy: 66.58%\n",
      "Epoch [26/30], Validation Loss: 1.0071, Validation Accuracy: 58.91%\n",
      "Epoch [27/30], Training Accuracy: 68.25%\n",
      "Epoch [27/30], Validation Loss: 0.9997, Validation Accuracy: 57.39%\n",
      "Epoch [28/30], Training Accuracy: 67.25%\n",
      "Epoch [28/30], Validation Loss: 0.9818, Validation Accuracy: 59.13%\n",
      "Epoch [29/30], Training Accuracy: 68.49%\n",
      "Epoch [29/30], Validation Loss: 0.9746, Validation Accuracy: 57.83%\n",
      "Epoch [30/30], Training Accuracy: 67.06%\n",
      "Epoch [30/30], Validation Loss: 1.0723, Validation Accuracy: 57.17%\n"
     ]
    }
   ],
   "source": [
    "class PseudoLabeledDataset(Dataset):\n",
    "    def __init__(self, data_list):\n",
    "        self.data_list = data_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data, label = self.data_list[idx]\n",
    "        return data, torch.tensor(label, dtype=torch.long)  # Explicitly casting to tensor\n",
    "\n",
    "# Initialize the Model, Loss, and Optimizer\n",
    "model = ConvNet(num_classes=4).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Number of training epochs\n",
    "num_epochs = 30\n",
    "\n",
    "# Pseudo-labeling threshold\n",
    "threshold = 0.95\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    \n",
    "    # Pseudo-labeling: get the pseudo-labels for the test data\n",
    "    model.eval()\n",
    "    pseudo_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data, _ in test_loader:\n",
    "            data = data.to(device)\n",
    "            outputs = F.softmax(model(data), dim=1)\n",
    "            _, predicted = outputs.max(1)\n",
    "            # Only keep predictions with confidence above the threshold\n",
    "            mask = outputs.max(1)[0] > threshold\n",
    "            for i in range(len(mask)):\n",
    "                if mask[i]:\n",
    "                    pseudo_labels.append((data[i].cpu(), predicted[i].item()))  # Using integer here, but it's casted to tensor when getting item\n",
    "\n",
    "    # Concatenate pseudo-labeled data with original training data\n",
    "    pseudo_dataset = PseudoLabeledDataset(pseudo_labels)\n",
    "    #combined_dataset = ConcatDataset([train_dataset, pseudo_dataset])\n",
    "    combined_dataset = ConcatDataset([tensor_label_train_subset, pseudo_dataset])\n",
    "\n",
    "    combined_loader = DataLoader(combined_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    # Training Loop with pseudo-labeled data\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(combined_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target.squeeze())  # Use squeeze in case of any singleton dimensions\n",
    "        \n",
    "        _, predicted_train = outputs.max(1)\n",
    "        correct_train += predicted_train.eq(target).sum().item()\n",
    "        total_train += target.size(0)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (batch_idx + 1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(combined_loader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_accuracy = 100. * correct_train / total_train\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Training Accuracy: {train_accuracy:.2f}%\")\n",
    "    \n",
    "    # Validation Loop\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            total_val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "   \n",
    "    val_accuracy = 100. * correct / len(val_subset)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd35bf19",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7f63262f",
   "metadata": {},
   "source": [
    "# 3. Evaluate your model using the developed software"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "687038bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "model.to(device)\n",
    "model.eval()  \n",
    "\n",
    "filenames = []\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():  \n",
    "    for data, filename in test_loader:  \n",
    "        data = data.to(device)\n",
    "        outputs = model(data)\n",
    "        _, predicted = torch.max(outputs, 1)  # Find the class index with the maximum value for each sample\n",
    "        filenames.extend(filename)\n",
    "        predictions.extend(predicted.cpu().numpy().tolist())\n",
    "\n",
    "model.train()  # Set the model back to training mode\n",
    "import pandas as pd\n",
    "\n",
    "df_output = pd.DataFrame({\n",
    "    'Filename': filenames,\n",
    "    'Prediction': predictions \n",
    "})\n",
    "\n",
    "df_output.to_csv('conv_predictions.csv', index=False, header=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5846bc",
   "metadata": {},
   "source": [
    "# 4. Compare results with [SCTL paper](https://www.mdpi.com/2076-2615/12/7/886/htm). Requirement: performance is better than VGG16: 66.8%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a626823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "62f12835",
   "metadata": {},
   "source": [
    "# 5. Write a four-page paper report using the shared LaTex template. Upload your paper to ResearchGate or Arxiv, and put your paper link here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f80f1b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f476372c",
   "metadata": {},
   "source": [
    "# 6. Grading rubric\n",
    "\n",
    "(1). Code ------- 20 points (you also need to upload your final model as a pt file)\n",
    "\n",
    "(2). Grammer ---- 20 points\n",
    "\n",
    "(3). Introduction & related work --- 10 points\n",
    "\n",
    "\n",
    "(4). Method  ---- 20 points\n",
    "\n",
    "(5). Results ---- 20 points\n",
    "\n",
    "     > = 66.8% -->10 points\n",
    "     < 40 % -->0 points\n",
    "     >= 40 % & < 66.8% --> 0.3731 point/percent\n",
    "     \n",
    "\n",
    "(6). Discussion - 10 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445593c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
